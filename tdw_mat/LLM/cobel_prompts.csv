type,prompt
measurement_first_order,"I'm $AGENT_NAME$. My friend $OPPO_NAME$ and I want to transport as many target objects as possible to the bed with the help of containers in a household scene with multiple rooms. Based on the message and my own visual observation, what $OPPO_NAME$'s mental knowledge now about object and my state? Remember that $OPPO_NAME$  don’t know $AGENT_NAME$’s Visual Observation. Use the rules below to refine and update $OPPO_NAME$'s mental knowledge:
$AGENT_NAME$’s Visual Observation: $VISUAL_OBSERVATION$
Message: 
$MESSAGE$
$OPPO_NAME$'s Historic Mental knowledge: 
$FIRST_ORDER_BELIEFS$
Belief rules: 
$BELIEF_RULES$
Just output in the rules form, without any analysis and reasoning progress. Remember the full name of objects , containers and rooms is in the form of <name>(id).  If you think $OPPO_NAME$ don't no any information, just put ""Unknown"" in the ().If nothing was in hand or container, just leave it Null."
measurement_zero_order,"
I'm $AGENT_NAME$. My friend $OPPO_NAME$ and I want to transport as many target objects as possible to the bed with the help of containers in a household scene with multiple rooms. Based on the message and my own visual observation, what information I should know? Use the rules below to refine and update my own historic mental knowledge:
$AGENT_NAME$’s Visual Observation: $VISUAL_OBSERVATION$
Message: 
$MESSAGE$
My Own Historic Mental knowledge: 
$ZERO_ORDER_BELIEFS$
Belief rules: 
$BELIEF_RULES$
Just output in the rules form, without any analysis and reasoning progress. Remember the full name of objects , containers and rooms is in the form of <name>(id). If you think I don't no any information, just put ""Unknown"" in the (). If nothing was in hand or container, just leave it Null."
prediction_first_order,"I'm $OPPO_NAME$. My friend $AGENT_NAME$ and I want to transport as many target objects as possible to the bed with the help of containers in a household scene with multiple rooms. Given my mental knowledge organized in a structured format. Please reason over these information and predict the goals’ perhaps states and then infer what should i will do next to maximize the efficiency. First give your reasons and answer me  with the subgoal only.

My own Mental Knowledge: 
$FIRST_ORDER_BELIEFS$
Reasons:
Subgoal:"
prediction_zero_order,"I'm $AGENT_NAME$ My friend $OPPO_NAME$. and I want to transport as many target objects as possible to the bed with the help of containers. Given my mental knowledge and the $OPPO_NAME$’s mental knowledge I believe. Please reason over these information and predict the goals’ perhaps states and then infer what should i will do next to maximize the efficiency. First give your reasons and answer me  with the subgoal only.
My own Mental Knowledge: 
$ZERO_ORDER_BELIEFS$
$OPPO_NAME$.’s Knowledge: 
$FIRST_ORDER_BELIEFS$
Reasons:
Subgoal:"
belief_awareness,"zero order belief:
 $ZERO_ORDER_BELIEFS$
first order beliefs: 
$FIRST_ORDER_BELIEFS$
Evaluate the different content first_order_belief and zero_order_belief, regardless of format and give a difference index from 0-10 0 for nearly identical 10 for large differences. And then list the difference parts between the two parts. Keep the output content the same as the original content Answer in this format and don't output additional analysis or summary:
- Difference score: 
- Different content: 
  - Zero_order_belief: 
  - First_order_belief:"
intuitive_planning,"I'm $AGENT_NAME$ My friend $OPPO_NAME$. and I want to transport as many target objects as possible to the bed with the help of containers. I can hold two things at a time, and they can be objects or containers. I can grasp containers and put objects into them to hold more objects at a time. Given my state, my previous actions, please help me choose the best available action according to my subgoal and previous actions. In order to achieve a subgoal, I may need to complete several actions, so you need to choose a best action based on previous actions to continue to complete this sub-goal. If I have done all actions need in the subgoal, just answer SUBGOAL DONE. 

My state: $MYSTATE$
Subgoal: $SUBGOAL$
Previous actions: $PREVIOUSACTIONS$
Available actions: $AVAILABLEACTIONS$
Answer:

"
init_beliefs,"I'm $AGENT_NAME$. My friend $OPPO_NAME$ and I want to transport as many target objects as possible to the bed with the help of containers in a household scene with multiple rooms . Given the goal and room list, please help me construct a mental knowledge template with the belief rules. The rules describe how the information in the task be formulated in a structured form to guide collaboration. Since you don’t know any information, just put Unknown in () to represent it. For items with an unknown quantity, generate only a single instance. Keep the tips in the rules like number constraints. Just output in the rules form, without any analysis and reasoning progress. Remember the full name of objects , containers and rooms is in the form of <name>(id). 
Here is an example in the view of Kate:
```
zero_order_beliefs(Kate)# my zero order belief
- target_object_state(orange(Unknown))
  - location(Unknown)
  - completion(Unknown)
- target_object_state(apple(Unknown))
  - location(Unknown)
  - completion(Unknown)
  ...
  ...
- container_state(Unknown)
  - location(Unknown)
  - contents[Unknown, Unknown, Unknown]
- agent_state(Kate)
  - location(Unknown)
  - subgoal(Unknown)
  - object_in_hand[Unknown, Unknown]
- agent_state(Bob)
  - location(Unknown)
  - subgoal(Unknown)
  - object_in_hand[Unknown, Unknown]
- room_state(Livingroom(1000))
  - exploration_state(Unknown)
...
...
- bed_location()
  - location(Unknown)

first_order_beliefs(Bob) # my first order belief about bob's belief
- target_object_state(orange(Unknown))
  - location(Unknown)
  - completion(Unknown)
...
...
- container_state(Unknown)
  - location(Unknown)
  - contents[Unknown, Unknown, Unknown]
- agent_state(Kate)
  - location(Unknown)
  - subgoal(Unknown)
  - object_in_hand[Unknown, Unknown]
- agent_state(Bob)
  - location(Unknown)
  - subgoal(Unknown)
  - object_in_hand[Unknown, Unknown]
- room_state(Livingroom(1000))
  - exploration_state(Unknown)
...
...
- bed_location()
  - location(Unknown)

```
Belief rules:
$BELIEF_RULES$
Goal:
$GOAL$
Room list:
$ROOM_LIST$

Answer in this format(including the annotation):
Zero order beliefs:# my zero order belief
First order beliefs:# my first order belief of ?agent's belief
"
adaptive_comm,"I’m $AGENT_NAME$. My friend $OPPO_NAME$ and I want to transport as many target objects as possible to the bed with the help of containers in a household scene with multiple rooms. Given the different knowledge between zero-order beliefs and first-order beliefs, please generate a message to inform collaborators to achieve a information alignment. You can generate the message according to the difference.


Belief difference: $BELIEF_DIFFERENCE$


Answer in this format:
{ to_agent1: message1,
to_agent2: message2 }"
measurement_first_order,"I'm $AGENT_NAME$. My friend $OPPO_NAME$ and I want to transport as many target objects as possible to the bed with the help of containers in a household scene with multiple rooms. Based on the message and my own visual observation, what $OPPO_NAME$'s mental knowledge now about object and my state? Remember that $OPPO_NAME$  don’t know $AGENT_NAME$’s Visual Observation. Use the rules below to refine and update $OPPO_NAME$'s mental knowledge:
$AGENT_NAME$’s Visual Observation: $VISUAL_OBSERVATION$
Message: 
$MESSAGE$
$OPPO_NAME$'s Historic Mental knowledge: 
$FIRST_ORDER_BELIEFS$
Belief rules: 
$BELIEF_RULES$
Just output in the rules form, without any analysis and reasoning progress. Remember the full name of objects , containers and rooms is in the form of <name>(id).  If you think $OPPO_NAME$ don't no any information, just put ""Unknown"" in the ().If nothing was in hand or container, just leave it Null."
measurement_zero_order,"
I'm $AGENT_NAME$. My friend $OPPO_NAME$ and I want to transport as many target objects as possible to the bed with the help of containers in a household scene with multiple rooms. Based on the message and my own visual observation, what information I should know? Use the rules below to refine and update my own historic mental knowledge:
$AGENT_NAME$’s Visual Observation: $VISUAL_OBSERVATION$
Message: 
$MESSAGE$
My Own Historic Mental knowledge: 
$ZERO_ORDER_BELIEFS$
Belief rules: 
$BELIEF_RULES$
Just output in the rules form, without any analysis and reasoning progress. Remember the full name of objects , containers and rooms is in the form of <name>(id). If you think I don't no any information, just put ""Unknown"" in the (). If nothing was in hand or container, just leave it Null."
misalignment_test,""
